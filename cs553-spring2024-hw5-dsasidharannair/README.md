### CS553 Cloud Computing Assignment 5 Repo

**Illinois Institute of Technology**

**Students**:

- Darshan Sasidharan Nair (dsasidharannair@hawk.iit.edu)

**How to Run**:

- For running the hashgen and vault set up two VMs names small-instance-spare and large-instance-spare and then run the run_non_hadoop.sh script. This would run all the programs one after the other records the times and then stores in in the csv file. I did not do the 32GB small instanceas my hashgen program takes more that 32GB of space at one point in the program which would cause problems for the VM
- You can see the results of the systat applications running in the background in the logs directory. You can also find the log for hasgen and vault in it.
- The images for the usage have been generated by the python program and stored in the primary results directory
- You can follow the instructions given in the report to setup a hadoop and spark cluster
- The spark configs I used for my setup can be found under configs for both the clusters
- Once you have a hadoop and spark cluster you can run the bash script run_hadoop_cluster1 to run the the map reduce program for the first cluster. I was unable to optimize the program to run for the second cluster as well even though I have already written a bash script for it.
- Fore more details on how my Map Reduce works check the report
- I was unable to complete my sparkSort as well. As even though it reads data and sorts it. I am unable to write it to a binary file. For more information on how it works and how I planned to complete it, check the report.

**Notes**:

- Ignore the vmname-log directories as they were supposed to store the sysstat and log output for the 64GB cases of Hadoop and Spark.
- The sort-hadoop stores the map reduce program as a maven project. You can find the pom.xml with the shade plugin and all the dependencies in that folder.
- I was unable to completly finish the assignment this time, as I was unable to figure out memory configs that would enable both hadoopsort and sparksort to run on all the clusters although both the programs work for smaller workloads across all the clusters
